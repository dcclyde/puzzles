{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Basic idea:\n",
    "In https://www.facebook.com/photo.php?fbid=1766949146696283 I hypothesized that good authors tend to (not sure if consciously?) use more complex vocabulary on \"setup\" parts, and less complex for \"exciting\" or \"emotional\" parts so the reader can feel swept along for the ride.\n",
    "\n",
    "To test this, let's compare complexity of first X% vs last X% for a whole bunch of Pulitzer-winning fiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textstat.textstat import textstat\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the sample from the website.\n",
    "test_data = \"\"\"Playing games has always been thought to be important to the development of well-balanced and creative children; however, what part, if any, they should play in the lives of adults has never been researched that deeply. I believe that playing games is every bit as important for adults as for children. Not only is taking time out to play games with our children and other adults valuable to building interpersonal relationships but is also a wonderful way to release built up tension.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.23\n",
      "12.5\n",
      "12.8\n",
      "11.61\n",
      "15.5\n",
      "7.49\n",
      "13\n",
      "13.833333333333334\n",
      "19.26146341463415\n",
      "12th and 13th grade\n"
     ]
    }
   ],
   "source": [
    "print(textstat.flesch_reading_ease(test_data))\n",
    "print(textstat.smog_index(test_data))\n",
    "print(textstat.flesch_kincaid_grade(test_data))\n",
    "print(textstat.coleman_liau_index(test_data))\n",
    "print(textstat.automated_readability_index(test_data))\n",
    "print(textstat.dale_chall_readability_score(test_data))\n",
    "print(textstat.difficult_words(test_data))\n",
    "print(textstat.linsear_write_formula(test_data))\n",
    "print(textstat.gunning_fog(test_data))\n",
    "print(textstat.text_standard(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See list of specific books at https://tinyurl.com/yczvzuzk\n",
    "# I hand-trimmed out front and back matter, and also threw out 1966 and 2000 since my cursory glance identified\n",
    "# them as collections of short stories, which aren't relevant to the experimental hypothesis.\n",
    "\n",
    "base_dir = (\n",
    "    '/mnt/Windows/Downloads/ff6/pulitzer_fiction/'\n",
    "    'Pulitzer Prize Winners Fiction eBooks Collection - '\n",
    "    '60 Large ebooks collections From 1920-2013 (ePub, Mobi)/'\n",
    "    'working/by_year/trimmed/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = {}\n",
    "for year in range(1918, 2013+1):\n",
    "    # try to grab text of that book\n",
    "    try:\n",
    "        with open(base_dir + str(year) + '.txt', 'r') as f:\n",
    "            file_dat = f.read()\n",
    "            file_dat = file_dat.replace('\\n', '')\n",
    "            dat[ year ] = file_dat\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat) # did imports work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function grabbing a specified chunk of a book, but cutting at word boundary\n",
    "def slice_frac(in_string, start_frac, end_frac):\n",
    "    start_pos = int(len(in_string) * 1.0 * start_frac)\n",
    "    while start_pos < len(in_string) and not in_string[start_pos].isspace():\n",
    "        start_pos += 1\n",
    "    \n",
    "    end_pos = int(len(in_string) * 1.0 * end_frac)\n",
    "    while end_pos < len(in_string) and not in_string[end_pos].isspace():\n",
    "        end_pos += 1\n",
    "    \n",
    "    \n",
    "    return in_string[ start_pos : end_pos ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify text_standard to return a numeric value for aggregation purposes.\n",
    "def text_standard_modified(string_in):\n",
    "    raw = textstat.text_standard(string_in)\n",
    "    return [\n",
    "        int(''.join(filter(str.isdigit, x)))\n",
    "        for x in raw.split()\n",
    "        if ''.join(filter(str.isdigit, x)) != ''\n",
    "    ][-1]\n",
    "\n",
    "readability_measures = {\n",
    "    \"flesch_reading_ease\": textstat.flesch_reading_ease,\n",
    "    \"smog_index\": textstat.smog_index,\n",
    "    \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade,\n",
    "    \"coleman_liau_index\": textstat.coleman_liau_index,\n",
    "    \"automated_readability_index\": textstat.automated_readability_index,\n",
    "    \"dale_chall_readability_score\": textstat.dale_chall_readability_score,\n",
    "    \"difficult_words\": textstat.difficult_words,\n",
    "    \"linsear_write_formula\": textstat.linsear_write_formula,\n",
    "    \"gunning_fog\": textstat.gunning_fog,\n",
    "    \"text_standard\": text_standard_modified,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_by_chunks(num_chunks):\n",
    "    results = {}\n",
    "    for year in dat:\n",
    "        print(year)\n",
    "        results[year] = {}\n",
    "\n",
    "        for chunk in range(num_chunks):\n",
    "            results[year][chunk] = {}\n",
    "            chunk_start = chunk / num_chunks\n",
    "            chunk_end = (chunk+1) / num_chunks\n",
    "\n",
    "            for measure_name, measure_function in readability_measures.items():\n",
    "                results[year][chunk][measure_name] = measure_function(\n",
    "                    slice_frac(\n",
    "                        dat[year],\n",
    "                        chunk_start,\n",
    "                        chunk_end\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1921\n",
      "1922\n",
      "1923\n",
      "1926\n",
      "1928\n",
      "1932\n",
      "1937\n",
      "1939\n",
      "1940\n",
      "1945\n",
      "1947\n",
      "1948\n",
      "1950\n",
      "1952\n",
      "1953\n",
      "1955\n",
      "1958\n",
      "1961\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1972\n",
      "1973\n",
      "1976\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1988\n",
      "1989\n",
      "1991\n",
      "1992\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2003\n",
      "2004\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2011\n",
      "2013\n",
      "1918\n",
      "1919\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1926\n",
      "1928\n",
      "1932\n",
      "1937\n",
      "1939\n",
      "1940\n",
      "1945\n",
      "1947\n",
      "1948\n",
      "1950\n",
      "1952\n",
      "1953\n",
      "1955\n",
      "1958\n",
      "1961\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1972\n",
      "1973\n",
      "1976\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1988\n",
      "1989\n",
      "1991\n",
      "1992\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2003\n",
      "2004\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2011\n",
      "2013\n",
      "1918\n",
      "1919\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1926\n",
      "1928\n",
      "1932\n",
      "1937\n",
      "1939\n",
      "1940\n",
      "1945\n",
      "1947\n",
      "1948\n",
      "1950\n",
      "1952\n",
      "1953\n",
      "1955\n",
      "1958\n",
      "1961\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1972\n",
      "1973\n",
      "1976\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1988\n",
      "1989\n",
      "1991\n",
      "1992\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2003\n",
      "2004\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2011\n",
      "2013\n",
      "1918\n",
      "1919\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1926\n",
      "1928\n",
      "1932\n",
      "1937\n",
      "1939\n",
      "1940\n",
      "1945\n",
      "1947\n",
      "1948\n",
      "1950\n",
      "1952\n",
      "1953\n",
      "1955\n",
      "1958\n",
      "1961\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1972\n",
      "1973\n",
      "1976\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1988\n",
      "1989\n",
      "1991\n",
      "1992\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2003\n",
      "2004\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2011\n",
      "2013\n",
      "1918\n",
      "1919\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1926\n",
      "1928\n",
      "1932\n",
      "1937\n",
      "1939\n",
      "1940\n",
      "1945\n",
      "1947\n",
      "1948\n",
      "1950\n",
      "1952\n",
      "1953\n",
      "1955\n",
      "1958\n",
      "1961\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1972\n",
      "1973\n",
      "1976\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1988\n",
      "1989\n",
      "1991\n",
      "1992\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2003\n",
      "2004\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2011\n",
      "2013\n",
      "1918\n",
      "1919\n"
     ]
    }
   ],
   "source": [
    "for nc in [5, 4, 3, 2, 1]:\n",
    "    results[nc] = readability_by_chunks(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(li):\n",
    "    return sum(li) / len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(num_chunks):\n",
    "    for measure_name in readability_measures:\n",
    "        diffs = [\n",
    "            results[num_chunks][year][num_chunks-1][measure_name] - results[num_chunks][year][0][measure_name]\n",
    "            for year in results[num_chunks]\n",
    "        ]\n",
    "        mean = avg( diffs )\n",
    "        sample_var = 1.0 / (len(diffs) - 1) * sum([(d - mean)**2 for d in diffs])\n",
    "        sample_stddev = sample_var ** (.5)\n",
    "\n",
    "        # what's the probability that the end is >= as complex as the start?\n",
    "        p_times_two = stats.ttest_1samp(diffs, 0.0).pvalue\n",
    "        p = p_times_two / 2  # ttest_1samp gives 2-sided p; we want 1-sided.\n",
    "        print(\n",
    "            '{measure_name}:\\n'\n",
    "            '\\tSample mean of (complexity of end - complexity of beginning): {mean}\\n'\n",
    "            '\\tProbability that true mean is NOT on the same side of 0.0: {p}\\n'.format(\n",
    "                measure_name=measure_name,\n",
    "                mean=mean,\n",
    "                p=p,\n",
    "            ),\n",
    "            end='',\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficult_words:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -90.83018867924528\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.03181393040556373\n",
      "gunning_fog:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.7691501709055725\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00012868179169424706\n",
      "smog_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.43396226415094324\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 8.033031247232298e-05\n",
      "linsear_write_formula:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -3.8540230340937884\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00046002492603910386\n",
      "flesch_kincaid_grade:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.6905660377358488\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0010848608430562442\n",
      "coleman_liau_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.35377358490566024\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00024760911799760776\n",
      "automated_readability_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.7981132075471699\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.000494680773818256\n",
      "flesch_reading_ease:\n",
      "\tSample mean of (complexity of end - complexity of beginning): 2.5996226415094346\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.002082487366389801\n",
      "dale_chall_readability_score:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.16226415094339625\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 2.5767976427333305e-05\n",
      "text_standard:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -1.0943396226415094\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0008129629144067909\n"
     ]
    }
   ],
   "source": [
    "aggregate(num_chunks=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficult_words:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -74.56603773584905\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.10358071076359542\n",
      "gunning_fog:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.5993359377715477\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0009281935858784745\n",
      "smog_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.34528301886792456\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00043825402857421765\n",
      "linsear_write_formula:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -3.3930718128831336\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0017018207675137589\n",
      "flesch_kincaid_grade:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.5056603773584907\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.005619256590865399\n",
      "coleman_liau_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.29150943396226425\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0015058848150027897\n",
      "automated_readability_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.6113207547169813\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.002973207791766625\n",
      "flesch_reading_ease:\n",
      "\tSample mean of (complexity of end - complexity of beginning): 1.8403773584905667\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.009966326710269775\n",
      "dale_chall_readability_score:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.1258490566037735\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0002804932038670606\n",
      "text_standard:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -1.1132075471698113\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00010021675083959076\n"
     ]
    }
   ],
   "source": [
    "aggregate(num_chunks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficult_words:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -99.45283018867924\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0696379109056587\n",
      "gunning_fog:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.49660277978671796\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0020787189925936325\n",
      "smog_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.28490566037735837\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0009226263891264874\n",
      "linsear_write_formula:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -3.0085454439505495\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.01767221592930925\n",
      "flesch_kincaid_grade:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.47547169811320755\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0056281006608893975\n",
      "coleman_liau_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.2998113207547171\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.00035336385029375585\n",
      "automated_readability_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.5207547169811322\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.005464763696012434\n",
      "flesch_reading_ease:\n",
      "\tSample mean of (complexity of end - complexity of beginning): 2.0824528301886795\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.003878931146672349\n",
      "dale_chall_readability_score:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.1786792452830188\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.004080071733784204\n",
      "text_standard:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.5849056603773585\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.004865365625192909\n"
     ]
    }
   ],
   "source": [
    "aggregate(num_chunks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difficult_words:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -101.45283018867924\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.046660429009561646\n",
      "gunning_fog:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.2739327285911698\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.0158647110204746\n",
      "smog_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.15849056603773568\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.005911514884857048\n",
      "linsear_write_formula:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -4.1168009401499965\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 9.790424617775001e-05\n",
      "flesch_kincaid_grade:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.2490566037735851\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.049671547475266246\n",
      "coleman_liau_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.17792452830188676\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.002222634161553051\n",
      "automated_readability_index:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.3000000000000001\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.026350497436458096\n",
      "flesch_reading_ease:\n",
      "\tSample mean of (complexity of end - complexity of beginning): 1.050566037735849\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.05231767835420706\n",
      "dale_chall_readability_score:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.13301886792452833\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.02062122625360837\n",
      "text_standard:\n",
      "\tSample mean of (complexity of end - complexity of beginning): -0.4716981132075472\n",
      "\tProbability that true mean is NOT on the same side of 0.0: 0.027529268847882073\n"
     ]
    }
   ],
   "source": [
    "aggregate(num_chunks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
